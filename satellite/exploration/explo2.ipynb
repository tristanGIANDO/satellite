{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a82097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite\\.venv\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m2 packages\u001b[0m \u001b[2min 149ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 148ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c111b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterator\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2955d727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JP2 files:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\giand\\AppData\\Local\\Temp\\ipykernel_13888\\4220903917.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(data)\n",
      "Processing JP2 files: 100%|██████████| 1/1 [00:10<00:00, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([4, 1, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Open 4 JP2 files using rasterio and convert to numpy array\n",
    "def open_jp2_as_numpy(file_path: Path) -> np.ndarray:\n",
    "    with rasterio.open(file_path) as src:\n",
    "        data = src.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class JP2Dataset(Dataset):\n",
    "    jp2_files: list[Path]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.jp2_files)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        jp2_file = self.jp2_files[idx]\n",
    "        data = open_jp2_as_numpy(jp2_file)\n",
    "        data = np.moveaxis(data, 0, -1)  # (H, W, C)\n",
    "\n",
    "        # Handle single-band images\n",
    "        if data.shape[-1] == 1:\n",
    "            data = data.squeeze(-1)\n",
    "\n",
    "        # Resize using numpy and torch (no PIL)\n",
    "        data = data.astype(np.float32)\n",
    "        data = torch.from_numpy(data)\n",
    "        if data.ndim == 2:\n",
    "            data = data.unsqueeze(0)  # (1, H, W)\n",
    "        else:\n",
    "            data = data.permute(2, 0, 1)  # (C, H, W)\n",
    "        data = torch.nn.functional.interpolate(\n",
    "            data.unsqueeze(0), size=(256, 256), mode=\"bilinear\", align_corners=False\n",
    "        ).squeeze(0)\n",
    "        data = data / 255.0\n",
    "        return torch.tensor(data)\n",
    "\n",
    "\n",
    "def create_dataloader(jp2_files: list[Path], batch_size: int = 4) -> DataLoader:\n",
    "    dataset = JP2Dataset(jp2_files)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def process_jp2_files(jp2_files: list[Path], batch_size: int = 4) -> None:\n",
    "    dataloader = create_dataloader(jp2_files, batch_size)\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Processing JP2 files\"):\n",
    "        # Here you can process the batch of images\n",
    "        # For demonstration, we will just print the shape of each batch\n",
    "        print(f\"Batch shape: {batch.shape}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example JP2 files (replace with your actual file paths)\n",
    "    jp2_files = [\n",
    "        Path(\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\nir\\B08.jp2\"\n",
    "        ),\n",
    "        Path(\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\red\\B04.jp2\"\n",
    "        ),\n",
    "        Path(\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\green\\B03.jp2\"\n",
    "        ),\n",
    "        Path(\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\blue\\B02.jp2\"\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # Process the JP2 files\n",
    "    process_jp2_files(jp2_files, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cafb72",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c86a0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class SimpleUNetV2(nn.Module):\n",
    "    def __init__(self, dropout_rate: float = 0.3) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(4, 32)\n",
    "        self.enc2 = self.conv_block(32, 64)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(64, 128)\n",
    "        self.dropout_bottleneck = nn.Dropout2d(p=self.dropout_rate)\n",
    "\n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        self.dropout_dec1 = nn.Dropout2d(p=self.dropout_rate)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(64, 32)\n",
    "\n",
    "        self.final = nn.Conv2d(32, 1, kernel_size=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def conv_block(self, in_ch: int, out_ch: int) -> nn.Sequential:\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: nn.Sequential) -> nn.Conv2d:\n",
    "        # Encode\n",
    "        x1 = self.enc1(x)  # (B, 32, H, W)\n",
    "        x2 = self.enc2(self.pool(x1))  # (B, 64, H/2, W/2)\n",
    "\n",
    "        # Bottleneck + dropout\n",
    "        x3 = self.bottleneck(self.pool(x2))\n",
    "        x3 = self.dropout_bottleneck(x3)  # (B, 128, H/4, W/4)\n",
    "\n",
    "        # Decode\n",
    "        x4 = self.up1(x3)\n",
    "        x4 = self.dec1(torch.cat([x4, x2], dim=1))\n",
    "        x4 = self.dropout_dec1(x4)\n",
    "\n",
    "        x5 = self.up2(x4)\n",
    "        x5 = self.dec2(torch.cat([x5, x1], dim=1))\n",
    "\n",
    "        return self.final(x5)  # (B, 1, H, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ea875f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "\n",
    "def read_sentinel_channels(red_path, green_path, blue_path, nir_path):\n",
    "    with (\n",
    "        rasterio.open(red_path) as red_src,\n",
    "        rasterio.open(green_path) as green_src,\n",
    "        rasterio.open(blue_path) as blue_src,\n",
    "        rasterio.open(nir_path) as nir_src,\n",
    "    ):\n",
    "        red = red_src.read(1)\n",
    "        green = green_src.read(1)\n",
    "        blue = blue_src.read(1)\n",
    "        nir = nir_src.read(1)\n",
    "    stacked = np.stack([red, green, blue, nir], axis=-1)\n",
    "    return stacked.astype(np.float32) / 10000  # Normalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fe1afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TileManager:\n",
    "    def __init__(self, tile_size=384, image_size=10180):\n",
    "        self.tile_size = tile_size\n",
    "        self.image_size = image_size\n",
    "        self.indices = self._compute_indices()\n",
    "\n",
    "    def _compute_indices(self):\n",
    "        indices = []\n",
    "        for y in range(0, self.image_size, self.tile_size):\n",
    "            for x in range(0, self.image_size, self.tile_size):\n",
    "                indices.append((y, x))\n",
    "        return indices\n",
    "\n",
    "    def extract_tiles(self, image):\n",
    "        tiles = []\n",
    "        valid_indices = []\n",
    "        for y, x in self.indices:\n",
    "            tile = image[y : y + self.tile_size, x : x + self.tile_size]\n",
    "\n",
    "            # Si bord droit/bas : pad avec 0\n",
    "            pad_y = self.tile_size - tile.shape[0]\n",
    "            pad_x = self.tile_size - tile.shape[1]\n",
    "            if pad_y > 0 or pad_x > 0:\n",
    "                tile = np.pad(tile, ((0, pad_y), (0, pad_x), (0, 0)), mode=\"constant\")\n",
    "\n",
    "            tiles.append(tile)\n",
    "            valid_indices.append((y, x))\n",
    "        return np.stack(tiles), valid_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99496bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def load_unet_model(path):\n",
    "    model = SimpleUNetV2()\n",
    "    model.load_state_dict(torch.load(path, map_location=\"cpu\"))  # ou \"cuda\" si dispo\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def infer_tiles(model, tiles, batch_size=32):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(tiles), batch_size):\n",
    "            batch = tiles[i : i + batch_size]\n",
    "            batch_tensor = torch.from_numpy(batch.transpose(0, 3, 1, 2))  # BCHW\n",
    "            output = model(batch_tensor).squeeze(1).numpy()\n",
    "            preds.append(output)\n",
    "    return np.concatenate(preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b0f5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_useful_tiles(predictions, tiles, indices, threshold=0.5, max_cloud_coverage=0.5):\n",
    "    useful_tiles = []\n",
    "    useful_indices = []\n",
    "    for pred, tile, idx in zip(predictions, tiles, indices):\n",
    "        low_pred_ratio = (pred < threshold).mean()\n",
    "        if low_pred_ratio < max_cloud_coverage:\n",
    "            useful_tiles.append(tile[:, :, :3])  # RGB only\n",
    "            useful_indices.append(idx)\n",
    "    return useful_tiles, useful_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prediction_state(pred_mask, indices, tile_size=350):\n",
    "    for y, x in indices:\n",
    "        pred_mask[y : y + tile_size, x : x + tile_size] = True\n",
    "    return pred_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_rgb_image(tiles, indices, image_shape=(10180, 10180, 3), tile_size=350):\n",
    "    full_image = np.zeros(image_shape, dtype=np.float32)\n",
    "    for tile, (y, x) in zip(tiles, indices):\n",
    "        full_image[y : y + tile_size, x : x + tile_size] = tile\n",
    "    return full_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "601b0ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_pipeline(image_paths_list, model_path):\n",
    "    model = load_unet_model(model_path)\n",
    "    tile_manager = TileManager()\n",
    "\n",
    "    prediction_mask = np.zeros((10180, 10180), dtype=bool)\n",
    "    all_rgb_tiles = []\n",
    "    all_indices = []\n",
    "\n",
    "    for red, green, blue, nir in image_paths_list:\n",
    "        print(f\"Processing: {red}, {green}, {blue}, {nir}\")\n",
    "        image = read_sentinel_channels(red, green, blue, nir)\n",
    "        tiles, indices = tile_manager.extract_tiles(image)\n",
    "\n",
    "        # Ne prédire que les tuiles non déjà validées\n",
    "        print(f\"Extracted {len(tiles)} tiles, {len(indices)} indices.\")\n",
    "        to_predict = [(t, i) for t, i in zip(tiles, indices) if not prediction_mask[i[0], i[1]]]\n",
    "        if not to_predict:\n",
    "            continue\n",
    "\n",
    "        print(f\"Predicting {len(to_predict)} new tiles.\")\n",
    "        t_tiles, t_indices = zip(*to_predict)\n",
    "        t_tiles = np.stack(t_tiles)\n",
    "\n",
    "        print(\"Running inference on tiles...\")\n",
    "\n",
    "        preds = infer_tiles(model, t_tiles, batch_size=16)\n",
    "\n",
    "        print(\"Filtering useful tiles...\")\n",
    "        useful_tiles, useful_indices = filter_useful_tiles(preds, t_tiles, t_indices)\n",
    "\n",
    "        print(f\"Found {len(useful_tiles)} useful tiles.\")\n",
    "        if not useful_tiles:\n",
    "            continue\n",
    "\n",
    "        all_rgb_tiles.extend(useful_tiles)\n",
    "        all_indices.extend(useful_indices)\n",
    "\n",
    "        print(f\"Updating prediction mask with {len(useful_indices)} indices.\")\n",
    "        prediction_mask = update_prediction_state(prediction_mask, useful_indices)\n",
    "\n",
    "        if prediction_mask.all():\n",
    "            break\n",
    "\n",
    "    print(\"Assembling final RGB image from useful tiles...\")\n",
    "\n",
    "    final_image = assemble_rgb_image(all_rgb_tiles, all_indices)\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03acb766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\red\\B04.jp2, C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\green\\B03.jp2, C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\blue\\B02.jp2, C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\nir\\B08.jp2\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.80 GiB for an array with shape (10980, 10980, 4) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_inference_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msentinel2-31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m2025-05-16\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mred\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mB04.jp2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msentinel2-31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m2025-05-16\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgreen\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mB03.jp2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msentinel2-31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m2025-05-16\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mblue\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mB02.jp2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msentinel2-31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m2025-05-16\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mnir\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mB08.jp2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msentinel2-31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m2025-05-26\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mred\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mB04.jp2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msentinel2-31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m2025-05-26\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgreen\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mB03.jp2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msentinel2-31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m2025-05-26\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mblue\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mB02.jp2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite_data\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msentinel2-31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m2025-05-26\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m31UDQ\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mnir\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mB08.jp2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC:\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mUsers\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mgiand\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mOneDrive\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mDocuments\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m__packages__\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m_perso\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msatellite\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mexploration\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43msimple_unet_v2_subset4000_epoch20.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mrun_inference_pipeline\u001b[39m\u001b[34m(image_paths_list, model_path)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m red, green, blue, nir \u001b[38;5;129;01min\u001b[39;00m image_paths_list:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mred\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgreen\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mblue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     image = \u001b[43mread_sentinel_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     tiles, indices = tile_manager.extract_tiles(image)\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Ne prédire que les tuiles non déjà validées\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mread_sentinel_channels\u001b[39m\u001b[34m(red_path, green_path, blue_path, nir_path)\u001b[39m\n\u001b[32m     15\u001b[39m     nir = nir_src.read(\u001b[32m1\u001b[39m)\n\u001b[32m     16\u001b[39m stacked = np.stack([red, green, blue, nir], axis=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstacked\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10000\u001b[39;49m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 1.80 GiB for an array with shape (10980, 10980, 4) and data type float32"
     ]
    }
   ],
   "source": [
    "run_inference_pipeline(\n",
    "    [\n",
    "        (\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\red\\B04.jp2\",\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\green\\B03.jp2\",\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\blue\\B02.jp2\",\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-16\\31UDQ\\nir\\B08.jp2\",\n",
    "        ),\n",
    "        (\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-26\\31UDQ\\red\\B04.jp2\",\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-26\\31UDQ\\green\\B03.jp2\",\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-26\\31UDQ\\blue\\B02.jp2\",\n",
    "            r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite_data\\sentinel2-31UDQ\\2025-05-26\\31UDQ\\nir\\B08.jp2\",\n",
    "        ),\n",
    "    ],\n",
    "    r\"C:\\Users\\giand\\OneDrive\\Documents\\__packages__\\_perso\\satellite\\satellite\\exploration\\models\\simple_unet_v2_subset4000_epoch20.pth\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
